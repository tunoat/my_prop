\selectlanguage{english}
\setlength{\parindent}{0.5cm}
\section{Experiment}
\subsection{Experiment Setup}
The proposed models are evaluated by 5-fold cross validation on the 10,000 labeled sentences.
The classification of the complaints is evaluated by a weighted macro average of precision,
recall and F1-score over the nine categories.\footnote{The weights are defined as proportion of the samples of the categories.}
The average length of the training sentences is ten.
The parameters in RNN are optimized by ADAM \cite{DBLP:journals/corr/KingmaB14}
In denoising auto-encoder with corrupted word,
four sentences are duplicated for each sentence in the training data,
where 20\% of the words are replaced with the unknown word.
However, if the sentence is too short, that is the number of the words
in the sentence is less than four, only one duplicated sentence
is created with one word is changed to the unknown word.

\subsection{Result}
\begin{figure}[!h]
\centering
  \includegraphics[scale=0.3]{image/5.png}
  \caption{Comparison between with and without DACW on different RNN models.}
  \label{fig:5}
\end{figure}
Figure~\ref{fig:5} illustrates the F1-score of the different models at each epoch.
``lstm'' and ``gru'' represents the model of RNN,
the prefix ``bi'' means bi-directional RNN, ``dacw'' and ``wodacw''
stand for the model with and without denoising autoencoder
with corrupted word (DACW).
The solid and break lines represent the results on the training
and test data, respectively.
Table~\ref{table:1} shows the average of F1-score between
$20^{th}-30^{th}$ epochs for simple comparison between
the model with and without DACW for single and bidirectional models.
\input{1.tex}


From these results, we found that all bi-directional models provide better results
than single directional models.
One of the reasons is the flexibility of the word order in Thai language.
In English, the word order is almost always fixed as Subject-Verb-Object.
In contrast, both Subject-Verb-Object and Subject-Object-Verb are acceptable in Thai.
Moreover, an adjective can ap-pear before or after the head noun.
Since the word order in Thai is flexible,
bi-directional model may be appropriate to learn word sequence
and dependency between words that are useful for the classification.


Second, the models with DACW slightly out-performed the models without DACW.
The dif-ference between bi-lstm-dacw and bi-lstm-wodacw is verified by
McNemar's test. The p-value is 0.0003, indicating that the DACW can significantly
improve the F1 score.


\begin{figure}[!h]
\centering
  \includegraphics[scale=0.25]{image/6.png}
  \caption{Graph comparison among different bi-lstm architectures.}
  \label{fig:6}
\end{figure}
Since the best model was bi-lstm-dacw, we conduct further experiment by modifying
the LSTM gate to three other architectures: CIFG, peephole, and FGR.
Table~\ref{table:2} shows the average F1-score, while Figure~\ref{fig:6} 
shows the change of the F1-score against the number of epochs.
The solid and break lines represents the results on the training and test data,
respectively. 
Among all architectures, bi-lstm-cifg-dacw achieves the best 
result for a training set but underperforms on the test set
compared to other architectures. 
The bi-lstm-peephole-dacw provides the best result on the test set.
Meanwhile, the performance of bi-lstm-fgr-dacw is almost equivalent 
to the default architecture.
\input{2.tex}


Table~\ref{table:3} shows the precision, recall and F1-score
for each of nine category.
Most remarkable point is that bi-lstm-peephole-dacw could perform much better
(by 0.1 F1-score) than bi-lstm-wodacw for ``Others'' category. 
Note that ``Others'' category is rather hard to be classified even
for human since a wide variety of the expressions are used.
The overall F1-score of bi-lstm-wodacw was suppressed by the poor performance
on ``Others'' category. 
Using denoising autoencoder with corrupted word and peephole gate,
now we achieved the F1-score more than 90\%.
\input{3.tex}


Finally, the contribution of the three components (preprocessing, DACW and peephole)
are shown in Table~\ref{table:4}.
``bi-lstm-no rule'' represents the bi-directional LSTM without
using preprocessing rules.
Comparing it with bi-lstm-wodacw, the rules improve the F1-score by 0.0582.
The contribution of DACW can be seen by the difference between bi-lstm-dacw
and bi-lstm-wodacw, which is 0.0064.
Similarly, the contribution of the peephole can be evaluated by comparison
between bi-lstm-dacw and bi-lstm-peephole-dacw (0.0056).
These results indicate that preprocessing of the text is important
since the contribution of the preprocessing rules is the most remarkable.
\input{4.tex}


\subsection{Example}
Table~\ref{table:5} reveals several examples of the complaint classification.
The bold-underline characters mean the words or phrase that might
influence the prediction the most.
They are chosen from our intuition.
It shows that bi-lstm-wodacw cannot well handle an unseen word combination.
The phrase ``raise their tone'' and ``designed card'' in the third and
fourth sentences in Table~\ref{table:5} never appear in ``Staff quality'' and
``Others'' categories in the training sets.
While bi-lstm-wodacw failed to classify them correctly,
bi-lstml-peephole-dacw could do it thanks to its ability to handle
for the unseen words.
In the 5th sentence, the multiple use of the word ``slow'' suggests
that the category of this com-plaint is ``Timing'',
but its gold category is ``Process''.
The LSTM with peephole considers the number of times that the same 
word appears more heavily compared to the default LSTM. 
For the $6^th$ sentence, both models predict the category incorrectly 
since the phrase ``slow service'' is usually related to not 
``Timing'' but ``Staff quality''. 
Actually, this complaints may be related to both ``Timing'' and ``Staff quality''.
However, in our data set, only one category is annotated for each sentence.
Multiclass classification of the customer's complaints is an important future work.
\input{5.tex}